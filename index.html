<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VISY-REVE creates continuous imaged trajectories from discrete datasets.">
  <meta name="keywords" content="VISY-REVE, VBN, View-Synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VISY-REVE: Real-Time View Synthesis for Vision-Based Navigation</title>



  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VISY-REVE: View Synthesis for Real-Time Validation of Vision-Based Navigation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Marius Neuhalfen</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Jonathan Grzymisch</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Manuel Sánchez-Gestido</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>European Space Agency, ESTEC</span>
            <span class="author-block"><sup>2</sup>RWTH Aachen University</span>
            <span class="author-block"><sup>3</sup>École Centrale de Lille</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/marius-ne/VISY-REVE-PY"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- LinkedIn Link. -->
              <span class="link-block">
                <a href="https://www.linkedin.com/in/marius-neuhalfen/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                        <i class="fab fa-linkedin"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">VISY-REVE</span> turns discrete datasets into responsive, continuous trajectories
        in real time. 
      </h2>
    </div>
  </div>
</section>


<section class="section is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This work introduces VISY-REVE: a novel pipeline to validate image processing algorithms for Vision-Based Navigation. Traditional validation methods such as synthetic rendering or robotic testbed acquisition suffer from difficult setup and slow runtime. Instead, we propose augmenting image datasets in real-time with synthesized views at novel poses. This approach creates continuous trajectories from sparse, pre-existing datasets in open or closed-loop. In addition, we introduce a new distance metric between camera poses, the Boresight Deviation Distance, which is better suited for view synthesis than existing metrics. Using it, a method for increasing the density of image datasets is developed.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">


    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Contributions</h2>

        <!-- Re-rendering. -->
        <div class="content has-text-justified">
          <p>
            Our <b>key contributions</b> are the introduction of a real-time view synthesis pipeline and
            alongside this a novel distance metric between poses that is highly predictive of the quality
            of synthesized image.
          </p>
        </div>
        <div class="content has-text-centered">
            <figure class="image" style="display: inline-block; width: 75%;">
            <img src="./static/images/illustrations_linux2.png" alt="Animation placeholder image">
            </figure>
        </div>
        <!--/ Re-rendering. -->

        <h3 class="title is-3">Applications</h2>
        <div class="content has-text-justified">
          <p>
            Our pipeline can be used to enable <b>closed-loop</b> testing from existing,
            <b>sparse</b> datasets, thereby avoiding time-consuming synthetic rendering or 
            tedious setup of closed-loop operations in a facility.
          </p>
        </div>

        <h3 class="title is-3">View Synthesis Methods</h2>
        <div class="content has-text-justified">
          <p>
            We use traditional, analytic view synthesis methods to transform source views of 
            an existing dataset into novel views. We propose two methods, one that favors fast
            computation while the other favors accurate synthesis.
          </p>
        </div>
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <figure class="image" style="display: inline-block; width: 90%;">
              <img src="./static/images/transform2DPipeline_V4.png" alt="Animation placeholder image 1">
            </figure>
          </div>
          <div class="column has-text-centered">
            <figure class="image" style="display: inline-block; width: 90%;">
              <img src="./static/images/transform3DPipeline_V3.png" alt="Animation placeholder image 2">
            </figure>
          </div>
        </div>

        <div class="content has-text-justified">
          <p>
            The novel distance metric that we introduce is called the <b>Boresight Deviation Distance</b>. 
            It has been designed to only consider the important degrees of freedom that most effect the 
            quality of synthesized views. This has two main advantages: 1. It enables choosing optimal nearest-neighbor
            views to perform view synthesis; 2. It enables creating more liberal performance models.
          </p>
          <p>
            Below you can see the intuition for this new metric as well as its 3D plot.
          </p>
        </div>
        <div class="columns is-centered">
        <div class="column is-two-thirds has-text-centered">
          <figure class="image" style="display: inline-block; width: 90%;">
            <img src="./static/images/bddillustration.png" alt="Animation placeholder image 1">
          </figure>
        </div>
        <div class="column is-one-third has-text-centered">
          <figure class="image" style="display: inline-block; width: 90%;">
            <img src="./static/images/NPD_3D_wo_BGV2.png" alt="Animation placeholder image 2">
          </figure>
        </div>
      </div>

      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{visyReve2025Neuhalfen,
  author    = {Neuhalfen, Marius and Grzymisch, Jonathan and Sanchez-Gestido, Manuel},
  title     = {Enabling Robust, Real-Time Verification of Vision-Based Navigation through View Synthesis},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/marius-ne/VISY-REVE-PY" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is a fork of the NERFIES website, which is available at <a href="https://nerfies.github.io/">https://nerfies.github.io/</a> 
            with its source code public at <a href="https://github.com/nerfies/nerfies.github.io">https://github.com/nerfies/nerfies.github.io</a>.
            We kindly thank its authors for allowing us to use it.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
